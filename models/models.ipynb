{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import argparse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\"Load the pre-trained KNN model from disk.\"\"\"\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    return model\n",
    "\n",
    "def load_scaler(scaler_path):\n",
    "    \"\"\"Load the saved StandardScaler from disk.\"\"\"\n",
    "    with open(scaler_path, 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "    return scaler\n",
    "\n",
    "def preprocess_data(data):\n",
    "    \"\"\"\n",
    "    Preprocess the input data by selecting the feature columns.\n",
    "    Make sure these are the same columns used during training.\n",
    "    \"\"\"\n",
    "    feature_cols = ['High', 'Low', 'Open', 'Volume']\n",
    "    X = data[feature_cols]\n",
    "    return X\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Make predictions on new stock data using a pre-trained KNN model.')\n",
    "    parser.add_argument('--data_path', type=str, required=True,\n",
    "                        help='Path to the CSV file with new stock data')\n",
    "    parser.add_argument('--model_path', type=str, default='backend/models/knn_model.pkl',\n",
    "                        help='Path to the saved KNN model file')\n",
    "    parser.add_argument('--scaler_path', type=str, default='backend/models/scaler.pkl',\n",
    "                        help='Path to the saved StandardScaler file')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "\n",
    "    args.model_path = \"/Users/devshah/Documents/WorkSpace/University/year 3/CSC392/Trading_Simulator/backend/models/knn_model.pkl\"\n",
    "    args.\n",
    "    \n",
    "    # Load new stock data\n",
    "    data = pd.read_csv(args.data_path)\n",
    "    \n",
    "    # Preprocess the new data\n",
    "    X_new = preprocess_data(data)\n",
    "    \n",
    "    # Load the model and scaler\n",
    "    model = load_model(args.model_path)\n",
    "    scaler = load_scaler(args.scaler_path)\n",
    "    \n",
    "    # Scale the new features using the saved scaler\n",
    "    X_new_scaled = scaler.transform(X_new)\n",
    "    \n",
    "    # Make predictions using the loaded model\n",
    "    predictions = model.predict(X_new_scaled)\n",
    "    \n",
    "    # Append the predictions to the dataframe\n",
    "    data['Predicted_Close'] = predictions\n",
    "    \n",
    "    # Output the predictions\n",
    "    print(data[['Predicted_Close']])\n",
    "    \n",
    "    # Optionally, save predictions to a new CSV file\n",
    "    output_path = os.path.splitext(args.data_path)[0] + '_predictions.csv'\n",
    "    data.to_csv(output_path, index=False)\n",
    "    print(f\"Predictions saved to {output_path}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
